{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cogs118b final project.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyNTQiVZ2GHN",
        "outputId": "0642705a-bd63-480b-fe13-1c8e0fd49c87"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Nt-DmogQaZ"
      },
      "source": [
        "#pip install tensorflow==2.4.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1gWkeWk2GHU"
      },
      "source": [
        "train_orig = pd.read_csv('Corona_NLP_train.csv', encoding = 'latin1')\n",
        "test_orig = pd.read_csv('Corona_NLP_test.csv',encoding = 'latin1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tURTr1yM2GHV"
      },
      "source": [
        "# Preprocess start here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FBHfg-C2GHV"
      },
      "source": [
        "train_orig=train_orig[['OriginalTweet','Sentiment']]\n",
        "test_orig=test_orig[['OriginalTweet','Sentiment']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v45FfRl92GHV"
      },
      "source": [
        "#pd.isnull(train_orig).sum()\n",
        "#pd.isnull(test_orig).sum()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEI3b5Ex2GHV"
      },
      "source": [
        "train_orig = train_orig.dropna()\n",
        "test_orig = test_orig.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCOdw7n2GHW"
      },
      "source": [
        "def remove_urls(input_text):\n",
        "    input_text=str(input_text)\n",
        "    result=re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
        "    return result\n",
        "\n",
        "def remove_nonASCII(string_):\n",
        "    printable = set(string.printable)\n",
        "    punctuation = set(string.punctuation)\n",
        "    #res=''.join(filter(lambda x: x not in printable, string_))\n",
        "    r = ''.join([c for c in string_ if (c in printable and c not in punctuation)])\n",
        "    return r\n",
        "\n",
        "def remove_speChar(string):\n",
        "    if '\\r' in string:\n",
        "        string=string.replace('\\r', ' ')\n",
        "    if  '\\n' in string:\n",
        "        string=string.replace('\\n', ' ')\n",
        "    return string\n",
        "\n",
        "def remove_stopwowrds(string):\n",
        "  r = ' '.join([c for c in string.split() if c not in stop_words])\n",
        "  return r"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3fzPP_l2GHW"
      },
      "source": [
        "train_orig['NewTweet']=train_orig.apply(lambda row: remove_urls(row['OriginalTweet']), axis=1)\n",
        "test_orig['NewTweet']=test_orig.apply(lambda row: remove_urls(row['OriginalTweet']), axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "js38UZhd2GHW",
        "outputId": "7d97d3a0-1ce8-45ec-aa97-2173d7e7cd84"
      },
      "source": [
        "train_orig.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewTweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv and and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cashier at grocery store was sharing his insig...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Cashier at grocery store was sharing his insig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>For corona prevention,we should stop to buy th...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>For corona prevention,we should stop to buy th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       OriginalTweet  ...                                           NewTweet\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...  ...           @MeNyrbie @Phil_Gahan @Chrisitv and and \n",
              "1  advice Talk to your neighbours family to excha...  ...  advice Talk to your neighbours family to excha...\n",
              "2  Coronavirus Australia: Woolworths to give elde...  ...  Coronavirus Australia: Woolworths to give elde...\n",
              "3  My food stock is not the only one which is emp...  ...  My food stock is not the only one which is emp...\n",
              "4  Me, ready to go at supermarket during the #COV...  ...  Me, ready to go at supermarket during the #COV...\n",
              "5  As news of the regionÂs first confirmed COVID...  ...  As news of the regionÂs first confirmed COVID...\n",
              "6  Cashier at grocery store was sharing his insig...  ...  Cashier at grocery store was sharing his insig...\n",
              "7  Was at the supermarket today. Didn't buy toile...  ...  Was at the supermarket today. Didn't buy toile...\n",
              "8  Due to COVID-19 our retail store and classroom...  ...  Due to COVID-19 our retail store and classroom...\n",
              "9  For corona prevention,we should stop to buy th...  ...  For corona prevention,we should stop to buy th...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4xHw8G42GHX"
      },
      "source": [
        "train_orig['NewTweet']=train_orig.apply(lambda row: remove_nonASCII(row['NewTweet']), axis=1)\n",
        "test_orig['NewTweet']=test_orig.apply(lambda row: remove_nonASCII(row['NewTweet']), axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "VakdtxUV2GHX",
        "outputId": "856866cb-5fed-404a-d094-5b1a746c40f6"
      },
      "source": [
        "train_orig.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewTweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>MeNyrbie PhilGahan Chrisitv and and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Coronavirus Australia Woolworths to give elder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>Me ready to go at supermarket during the COVID...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       OriginalTweet  ...                                           NewTweet\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...  ...               MeNyrbie PhilGahan Chrisitv and and \n",
              "1  advice Talk to your neighbours family to excha...  ...  advice Talk to your neighbours family to excha...\n",
              "2  Coronavirus Australia: Woolworths to give elde...  ...  Coronavirus Australia Woolworths to give elder...\n",
              "3  My food stock is not the only one which is emp...  ...  My food stock is not the only one which is emp...\n",
              "4  Me, ready to go at supermarket during the #COV...  ...  Me ready to go at supermarket during the COVID...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG1KBuNUodII"
      },
      "source": [
        "#train_orig['NewTweet']=train_orig.apply(lambda row: remove_stopwowrds(row['NewTweet']), axis=1)\n",
        "#test_orig['NewTweet']=test_orig.apply(lambda row: remove_stopwowrds(row['NewTweet']), axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "yhDe3gLqoso-",
        "outputId": "e6183d7a-7281-4ce6-c763-7794d114ca52"
      },
      "source": [
        "train_orig.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewTweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>MeNyrbie PhilGahan Chrisitv and and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Coronavirus Australia Woolworths to give elder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>Me ready to go at supermarket during the COVID...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       OriginalTweet  ...                                           NewTweet\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...  ...               MeNyrbie PhilGahan Chrisitv and and \n",
              "1  advice Talk to your neighbours family to excha...  ...  advice Talk to your neighbours family to excha...\n",
              "2  Coronavirus Australia: Woolworths to give elde...  ...  Coronavirus Australia Woolworths to give elder...\n",
              "3  My food stock is not the only one which is emp...  ...  My food stock is not the only one which is emp...\n",
              "4  Me, ready to go at supermarket during the #COV...  ...  Me ready to go at supermarket during the COVID...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi4OBE-42GHX"
      },
      "source": [
        "train_orig['NewTweet'] = train_orig['NewTweet'].str.lower()\n",
        "train_orig['NewTweet']=train_orig.apply(lambda row: remove_speChar(row['NewTweet']), axis=1)\n",
        "train_ls=train_orig['NewTweet'].tolist()\n",
        "train = train_orig\n",
        "\n",
        "test_orig['NewTweet'] = test_orig['NewTweet'].str.lower()\n",
        "test_orig['NewTweet']=test_orig.apply(lambda row: remove_speChar(row['NewTweet']), axis=1)\n",
        "test_ls=test_orig['NewTweet'].tolist()\n",
        "test = test_orig"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj0QZfIr2GHY"
      },
      "source": [
        "# change 5 categories to 3; change \"netural\":0, \"positive\":1,\"negative\":2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5wDJ6s72GHY"
      },
      "source": [
        "train['Sentiment'].unique()\n",
        "#change five categories to three \n",
        "train_df = train\n",
        "test_df = test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUzaw5x-2GHY"
      },
      "source": [
        "def change_sen(sentiment):\n",
        "    if sentiment == \"Extremely Positive\":\n",
        "        return 'positive'\n",
        "    elif sentiment == \"Extremely Negative\":\n",
        "        return 'negative'\n",
        "    elif sentiment == \"Positive\":\n",
        "        return 'positive'\n",
        "    elif sentiment == \"Negative\":\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'netural'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "67VKS_qv2GHY",
        "outputId": "928bfeec-60ac-49d3-b976-f243476b36e0"
      },
      "source": [
        "sns.countplot(train['Sentiment'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa7512260f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVJ0skDx2GHZ"
      },
      "source": [
        "train_df['Sentiment'] = train_df['Sentiment'].apply(lambda x: change_sen(x))\n",
        "test_df['Sentiment'] = test_df['Sentiment'].apply(lambda x: change_sen(x))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "dyoTwp872GHZ",
        "outputId": "91e624d8-8990-4bee-8ded-7ba7b3618f24"
      },
      "source": [
        "sns.countplot(train_df['Sentiment'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa74d719518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LHfkIHC2GHZ"
      },
      "source": [
        "label = {\"netural\":0, \"positive\":1,\"negative\":2}\n",
        "train_df['Sentiment'] = train_df['Sentiment'].map(label)\n",
        "test_df['Sentiment']  = test_df['Sentiment'].map(label)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovSIsgJl2GHZ"
      },
      "source": [
        "# tokenization & word count & vocab_to_int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lMshi0j2GHZ"
      },
      "source": [
        "# count frequency of words in counts; \n",
        "#create word dict:word_to_int based on counts \n",
        "def word_dict(ls, type_):\n",
        "    wordCount = defaultdict(int)\n",
        "    punctuation = set(string.punctuation)\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    for d in ls:\n",
        "        #d = tokenizer.tokenize(d)\n",
        "        #d = [token for token in d if token not in stop_words]\n",
        "        for w in d.split():\n",
        "          #if w not in stop_words:\n",
        "            wordCount[w] += 1\n",
        "    #count is counting the word frequency and sort from most frequent to least\n",
        "    counts = [(wordCount[w], w) for w in wordCount]\n",
        "    counts.sort()\n",
        "    counts.reverse()\n",
        "    words_list = [x[1] for x in counts]\n",
        "    words = set(words_list)\n",
        "    vocab_to_int={w:i+1 for i,(c,w) in enumerate(counts)}\n",
        "    if type_ =='v':\n",
        "        return vocab_to_int\n",
        "    else:\n",
        "        return counts"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icIpqLvt2GHa"
      },
      "source": [
        "train_c = word_dict(train_df['NewTweet'], 'c')\n",
        "train_vocab_to_int = word_dict(train_df['NewTweet'], 'v')\n",
        "\n",
        "test_c = word_dict(test_df['NewTweet'], 'c')\n",
        "test_vocab_to_int = word_dict(test_df['NewTweet'], 'v')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQDhYARP2j3c",
        "outputId": "5a0afbad-a500-4d20-bb83-fe339fd41875"
      },
      "source": [
        "train_c[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(44785, 'the'),\n",
              " (38339, 'to'),\n",
              " (23976, 'and'),\n",
              " (21512, 'of'),\n",
              " (19325, 'a'),\n",
              " (19127, 'in'),\n",
              " (17995, 'coronavirus'),\n",
              " (16836, 'covid19'),\n",
              " (14041, 'for'),\n",
              " (12246, 'is')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCoGfqt23fSh",
        "outputId": "d2d7a7bb-fa52-4889-a40f-258c0aa422b0"
      },
      "source": [
        "vocab_to_int_list = [(train_vocab_to_int[w], w) for w in train_vocab_to_int]\n",
        "vocab_to_int_list[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'the'),\n",
              " (2, 'to'),\n",
              " (3, 'and'),\n",
              " (4, 'of'),\n",
              " (5, 'a'),\n",
              " (6, 'in'),\n",
              " (7, 'coronavirus'),\n",
              " (8, 'covid19'),\n",
              " (9, 'for'),\n",
              " (10, 'is')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-rmimgj2GHa"
      },
      "source": [
        "#tweet int: list contains list of sentence in which words convert to numerical values\n",
        "def w_to_num(vocab_to_int,ls):\n",
        "    tweet_int = []\n",
        "    for review in ls:\n",
        "        cur_ls=[]\n",
        "        for word in review.split():\n",
        "            if word not in vocab_to_int.keys():\n",
        "                cur_ls.append(0)\n",
        "            else:\n",
        "                cur_ls.append(vocab_to_int[word])\n",
        "        tweet_int.append(cur_ls)\n",
        "    return tweet_int"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cITAeUzu2GHa"
      },
      "source": [
        "train_int = w_to_num(train_vocab_to_int,train_ls)\n",
        "\n",
        "test_int = w_to_num(train_vocab_to_int,test_ls)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mep8nEO4_eUI",
        "outputId": "4dbe46a2-23d6-4be8-9b81-723a1cd53dc7"
      },
      "source": [
        "train_int[:2]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[39630, 35439, 15896, 3, 3],\n",
              " [516,\n",
              "  907,\n",
              "  2,\n",
              "  33,\n",
              "  2598,\n",
              "  270,\n",
              "  2,\n",
              "  2958,\n",
              "  902,\n",
              "  1275,\n",
              "  1130,\n",
              "  455,\n",
              "  397,\n",
              "  21,\n",
              "  902,\n",
              "  1275,\n",
              "  4,\n",
              "  2598,\n",
              "  1228,\n",
              "  4122,\n",
              "  3719,\n",
              "  5095,\n",
              "  499,\n",
              "  42,\n",
              "  51,\n",
              "  48,\n",
              "  2458,\n",
              "  49,\n",
              "  14229,\n",
              "  3377,\n",
              "  193,\n",
              "  4,\n",
              "  1080,\n",
              "  3510,\n",
              "  50,\n",
              "  34,\n",
              "  114,\n",
              "  240]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Daz4QrlA2GHb"
      },
      "source": [
        "tweet_Int<- x_train; sentiment <- train_df[..]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xUk7ABms5Ho"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCiEuV6Qs0v5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b0cc4847-23c9-4233-bede-0ce6b39e59e8"
      },
      "source": [
        "'''\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df['NewTweet'])\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(train_df['NewTweet'])\n",
        "x_test = tokenizer.texts_to_sequences(test_df['NewTweet'])\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=60, padding='post')\n",
        "x_test = pad_sequences(x_test, maxlen=60, padding='post')\n",
        "'''"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(train_df['NewTweet'])\\nvocab_length = len(tokenizer.word_index) + 1\\n\\nx_train = tokenizer.texts_to_sequences(train_df['NewTweet'])\\nx_test = tokenizer.texts_to_sequences(test_df['NewTweet'])\\n\\nx_train = pad_sequences(x_train, maxlen=60, padding='post')\\nx_test = pad_sequences(x_test, maxlen=60, padding='post')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebRdFQWvEDyR"
      },
      "source": [
        "\n",
        "#test_df['NewTweet'][0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "GQ2s3iJotjsb",
        "outputId": "77c88a36-c6ce-447f-c5bb-14a5670c30e2"
      },
      "source": [
        "'''\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_length, 16, input_length=60),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport keras\\nfrom keras.models import Sequential\\nimport tensorflow as tf\\nmodel = tf.keras.Sequential([\\n    tf.keras.layers.Embedding(vocab_length, 16, input_length=60),\\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\\n    tf.keras.layers.GlobalAveragePooling1D(),\\n    tf.keras.layers.Dropout(0.3),\\n    tf.keras.layers.Dense(64, activation=\\'relu\\'),\\n    tf.keras.layers.Dropout(0.3),\\n    tf.keras.layers.Dense(3, activation=\\'softmax\\')\\n])\\n\\nmodel.compile(loss=\\'categorical_crossentropy\\',optimizer=\"adam\",metrics=[\\'accuracy\\'])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnDF8_xrulNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "772502af-c766-452e-9bd8-9890f5639b5c"
      },
      "source": [
        "'''\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(train_df['Sentiment'], 3)\n",
        "y_test = to_categorical(test_df['Sentiment'], 3)\n",
        "'''"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom keras.utils import to_categorical\\n\\ny_train = to_categorical(train_df['Sentiment'], 3)\\ny_test = to_categorical(test_df['Sentiment'], 3)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8sY89WvERO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5561bf52-5404-4837-8ea3-f7b84d1b7852"
      },
      "source": [
        "'''\n",
        "num_epochs = 10\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, \n",
        "                    validation_data=(x_test, y_test))\n",
        "'''"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nnum_epochs = 10\\nhistory = model.fit(x_train, y_train, epochs=num_epochs, \\n                    validation_data=(x_test, y_test))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFupGMok-LUo"
      },
      "source": [
        "#print(model.summary())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfbXLcts2GHb"
      },
      "source": [
        "## Plot Tweet length distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPtnz7G2KRoD"
      },
      "source": [
        "#accr = model.evaluate(X_test,y_test)\n",
        "#print(accr)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RCD9JOR2GHb"
      },
      "source": [
        "def plot_tweet(ls,string):\n",
        "    reviews_len = [len(x) for x in ls]\n",
        "    pd.Series(reviews_len).hist()\n",
        "    plt.title(string + ' tweet length distribution: word length in tweet VS frequency ')\n",
        "    plt.xlabel('legnth of word in each tweet')\n",
        "    plt.ylabel('frequeccy')\n",
        "    plt.show()\n",
        "    print(pd.Series(reviews_len).describe())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd3orzfv2GHb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "8da9301a-f436-45a6-c3df-0f6db76d8bf8"
      },
      "source": [
        "plot_tweet(train_int,'train')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "count    41157.000000\n",
            "mean        29.613674\n",
            "std         11.704519\n",
            "min          0.000000\n",
            "25%         20.000000\n",
            "50%         31.000000\n",
            "75%         39.000000\n",
            "max         64.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY1XolVt2GHc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "36426d77-0119-47f8-a387-c3d4d6c51f5b"
      },
      "source": [
        "plot_tweet(test_int,'test')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "count    3798.000000\n",
            "mean       32.086888\n",
            "std        11.840029\n",
            "min         2.000000\n",
            "25%        23.000000\n",
            "50%        33.000000\n",
            "75%        42.000000\n",
            "max        62.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X97qQg1q2GHd"
      },
      "source": [
        "# Padding / Truncating data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stCvkMZi2GHd"
      },
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "    \n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "        \n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = review + zeroes\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa0uijPU2GHe"
      },
      "source": [
        "#self define seq_length as 31(same as median, close to mean) \n",
        "THRESHOLD = 60\n",
        "feature_train = pad_features(train_int,THRESHOLD)\n",
        "#print(feature_ls)\n",
        "feature_test = pad_features(test_int,THRESHOLD)\n",
        "#we set the THRESHOLD so that all tweet length have the same length\n",
        "#for tweet shorter than length set them to zero;\n",
        "#for those longer: cut them to threshold"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BMLYPiSmNeC",
        "outputId": "694b56b2-a0c2-4fc8-9258-8862c8aecbec"
      },
      "source": [
        "feature_train[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([39630, 35439, 15896,     3,     3,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6XU2j9VlrTw"
      },
      "source": [
        "#pd.DataFrame(feature_train).to_csv(\"x_train.csv\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmQQxRu-mEWN"
      },
      "source": [
        "#pd.DataFrame(feature_test).to_csv(\"x_test.csv\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw_MCKIR2GHe"
      },
      "source": [
        "# split train & validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUFfd4g2GHf"
      },
      "source": [
        "#x_test[0]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAvmlMyEzxJL"
      },
      "source": [
        "#X_test[0]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c2_hEOJr6EST",
        "outputId": "66fb1d8c-3709-458b-9589-0a75af454db1"
      },
      "source": [
        "test_df['NewTweet'][0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'trending new yorkers encounter empty supermarket shelves pictured wegmans in brooklyn soldout online grocers foodkick maxdelivery as coronavirusfearing shoppers stock up '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0tox9gi2GHf"
      },
      "source": [
        "#split train and validation data (80,20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(feature_train, train_df['Sentiment'].to_numpy(), test_size=0.2, random_state=42)\n",
        "X_test, y_test = feature_test, test_df['Sentiment'].to_numpy()\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jtE7mb4hreR"
      },
      "source": [
        "#vocab_size = len(train_vocab_to_int)+1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8y56oyhbpPN",
        "outputId": "5708a352-31f6-42de-bb15-4242d1297eb4"
      },
      "source": [
        "X_train[10]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,   407,   950,  1643,  6659,    17,   425,   596,     1,\n",
              "        2854,  1390,     3,     1,   391,     6,    93,    16,    15,\n",
              "          73,   612,    44,     1, 56741,   119,    96, 10996, 13089,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "e0GFBkXdHmDe",
        "outputId": "2ac832c2-ccf4-4864-a698-d74f39f71bed"
      },
      "source": [
        "'''\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 16, input_length=60),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "'''"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport keras\\nfrom keras.models import Sequential\\nimport tensorflow as tf\\nmodel = tf.keras.Sequential([\\n    tf.keras.layers.Embedding(vocab_size, 16, input_length=60),\\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\\n    tf.keras.layers.GlobalAveragePooling1D(),\\n    tf.keras.layers.Dropout(0.3),\\n    tf.keras.layers.Dense(64, activation=\\'relu\\'),\\n    #tf.keras.layers.Dropout(0.3),\\n    tf.keras.layers.Dense(3, activation=\\'softmax\\')\\n])\\n# opt = tf.keras.optimizers.Adam(learning_rate=0.01)\\nmodel.compile(loss=\\'categorical_crossentropy\\',optimizer=\"adam\",metrics=[\\'accuracy\\'])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW-_ldvPHpTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b92f3ad9-5fc4-4cac-98bc-1569f2c1a0d4"
      },
      "source": [
        "'''\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(train_df['Sentiment'], 3)\n",
        "#y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "'''"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom keras.utils import to_categorical\\ny = to_categorical(train_df['Sentiment'], 3)\\n#y_train = to_categorical(y_train, 3)\\ny_test = to_categorical(y_test, 3)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oEXCr5b9HtGx",
        "outputId": "5c7751c2-860c-4376-9dc9-5a5138bda00d"
      },
      "source": [
        "'''\n",
        "num_epochs = 10\n",
        "history = model.fit(feature_train, y, epochs=num_epochs, validation_data=(X_test, y_test))\n",
        "'''"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nnum_epochs = 10\\nhistory = model.fit(feature_train, y, epochs=num_epochs, validation_data=(X_test, y_test))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr103yNRIdb7"
      },
      "source": [
        "#accr = model.evaluate(X_test,y_test)\n",
        "#print(accr)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7__Jv7V32GHf"
      },
      "source": [
        "# data loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ihf1VlRF8wsa",
        "outputId": "12015e36-57d9-4667-8a71-bb6de445a5f9"
      },
      "source": [
        "'''\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df['NewTweet'])\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train_df['NewTweet'])\n",
        "X_test = tokenizer.texts_to_sequences(test_df['NewTweet'])\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=60, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=60, padding='post')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, train_df['Sentiment'].to_numpy(), test_size=0.2, random_state=42)\n",
        "y_test = test_df['Sentiment'].to_numpy()\n",
        "'''"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(train_df['NewTweet'])\\nvocab_length = len(tokenizer.word_index) + 1\\n\\nX_train = tokenizer.texts_to_sequences(train_df['NewTweet'])\\nX_test = tokenizer.texts_to_sequences(test_df['NewTweet'])\\n\\nX_train = pad_sequences(X_train, maxlen=60, padding='post')\\nX_test = pad_sequences(X_test, maxlen=60, padding='post')\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, train_df['Sentiment'].to_numpy(), test_size=0.2, random_state=42)\\ny_test = test_df['Sentiment'].to_numpy()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKuVh-099I_z"
      },
      "source": [
        "#X_test.shape"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMR1KfgL2GHf"
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train).cuda(), torch.from_numpy(y_train).cuda())\n",
        "valid_data = TensorDataset(torch.from_numpy(X_val).cuda(), torch.from_numpy(y_val).cuda())\n",
        "test_data = TensorDataset(torch.from_numpy(X_test).cuda(), torch.from_numpy(y_test).cuda())\n",
        "\n",
        "#PARAMETER TODO\n",
        "batch_size = 64 \n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13m3AKS2GHf",
        "outputId": "265695d8-f022-43a2-c420-cbb99eff64a0"
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([64, 60])\n",
            "Sample input: \n",
            " tensor([[1560, 3430,  526,  ...,    0,    0,    0],\n",
            "        [   8,   97, 1824,  ...,    0,    0,    0],\n",
            "        [  67,   91, 5707,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,   45, 1630,  ...,    0,    0,    0],\n",
            "        [  65,   70, 1512,  ...,    0,    0,    0],\n",
            "        [3948,  233, 1772,  ...,    0,    0,    0]], device='cuda:0')\n",
            "\n",
            "Sample label size:  torch.Size([64])\n",
            "Sample label: \n",
            " tensor([0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 1, 2, 0, 2, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0,\n",
            "        1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 0, 2,\n",
            "        2, 2, 2, 0, 0, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE4NsLlw2GHg"
      },
      "source": [
        "# The layers are as follows:\n",
        "0. Tokenize : This is not a layer for LSTM network but a mandatory step of converting our words into tokens (integers)  \n",
        "\n",
        "Embedding Layer: that converts our word tokens (integers) into embedding of specific size  \n",
        "\n",
        "LSTM Layer: defined by hidden state dims and number of layers  \n",
        "\n",
        "Fully Connected Layer: that maps output of LSTM layer to a desired output size  \n",
        "\n",
        "Sigmoid Activation Layer: that turns all output values in a value between 0 and 1  \n",
        "\n",
        "Output: Sigmoid output from the last timestep is considered as the final output of this network  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv-sMdXj2GHg"
      },
      "source": [
        "# define the model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkO6RPx2GHh"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.3):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True, bidirectional=True)\n",
        "        #self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # linear and sigmoid layers\n",
        "        #self.maxpool = nn.AdaptiveMaxPool1d(128)\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, output_size)\n",
        "        #self.sig = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        #print('inside nn')\n",
        "        #print(f'x size: {x.shape}')\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        #print(f'batch_size: {batch_size}')\n",
        "        x = x.long()\n",
        "        # embeddings and lstm_out\n",
        "        if(x.is_cuda==False):\n",
        "            x=x.cuda()\n",
        "        embeds = self.embedding(x)\n",
        "        #print(f'embeds shape: {embeds.shape}')\n",
        "\n",
        "        #lstm_out, hidden = self.gru(embeds, hidden)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        #print(f'lstm_out shape: {lstm_out.shape}')\n",
        "        lstm_out = torch.mean(lstm_out, dim=1)\n",
        "        #print(f'lstm_out shape: {lstm_out.shape}')\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        #print(f'lstm_out shape second: {lstm_out.shape}')\n",
        "        #out = self.maxpool(lstm_out)\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        #out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        \n",
        "        #print(f'fc output shape: {out.shape}')\n",
        "        # sigmoid function\n",
        "        #sig_out = self.sig(out)\n",
        "        #sig_out = self.relu(out)\n",
        "        sig_out = self.softmax(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        #sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out.view(batch_size, -1, output_size)\n",
        "\n",
        "        #print(f'sig_out shape: {sig_out.shape}')\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        #sig_out = torch.mean(sig_out, dim=1)\n",
        "        #sig_out = sig_out[:, -1, :]\n",
        "        #print(f'sig_out shape: {sig_out.shape}')\n",
        "        # return last sigmoid output and hidden state\n",
        "        #print('leave nn')\n",
        "        #print(f'final shape: {sig_out.shape}')\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tRVFkTn2GHi"
      },
      "source": [
        "# Train the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nExjcmf92GHi"
      },
      "source": [
        "## Instantiate the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6OLahBB2GHi",
        "outputId": "ffc76e31-2b67-42b4-f8bc-d6989b7c01d5"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(train_vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 3 \n",
        "embedding_dim = 16\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(60889, 16)\n",
            "  (lstm): LSTM(16, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXSC3yuj2GHj"
      },
      "source": [
        "# Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3uX9C722GHj",
        "outputId": "0c5d99d8-0181-4771-8efb-282fad532553"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "#criterion = nn.BCELoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "#scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 50 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "#         inputs = inputs.type(torch.LongTensor)\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        #print(output.squeeze())\n",
        "        #print(labels.float().shape)\n",
        "        labels_long = labels.type(torch.LongTensor).cuda()\n",
        "        #loss = criterion(output.squeeze(), labels.float())\n",
        "        loss = criterion(output.squeeze(), labels_long)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        #nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "                if inputs.device=='cpu':\n",
        "                    print(\"valid\")\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.type(torch.LongTensor).cuda()\n",
        "\n",
        "                inputs = inputs.type(torch.LongTensor)\n",
        "                #labels = labels.type(torch.LongTensor)\n",
        "                output, val_h = net(inputs, val_h)\n",
        "#                 print(val_h)\n",
        "                #val_loss = criterion(output.squeeze(), labels.float())\n",
        "                val_loss = criterion(output.squeeze(), labels)\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "    #scheduler.step()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50... Step: 100... Loss: 1.080938... Val Loss: 1.049574\n",
            "Epoch: 1/50... Step: 200... Loss: 1.051161... Val Loss: 1.048921\n",
            "Epoch: 1/50... Step: 300... Loss: 1.034920... Val Loss: 1.040418\n",
            "Epoch: 1/50... Step: 400... Loss: 1.058215... Val Loss: 1.034211\n",
            "Epoch: 1/50... Step: 500... Loss: 1.013101... Val Loss: 1.038827\n",
            "Epoch: 2/50... Step: 600... Loss: 1.043200... Val Loss: 1.034485\n",
            "Epoch: 2/50... Step: 700... Loss: 1.008132... Val Loss: 1.032272\n",
            "Epoch: 2/50... Step: 800... Loss: 0.995717... Val Loss: 1.033715\n",
            "Epoch: 2/50... Step: 900... Loss: 1.004509... Val Loss: 1.028787\n",
            "Epoch: 2/50... Step: 1000... Loss: 1.027104... Val Loss: 1.021171\n",
            "Epoch: 3/50... Step: 1100... Loss: 0.941970... Val Loss: 1.013619\n",
            "Epoch: 3/50... Step: 1200... Loss: 1.025471... Val Loss: 1.011045\n",
            "Epoch: 3/50... Step: 1300... Loss: 0.968650... Val Loss: 0.984007\n",
            "Epoch: 3/50... Step: 1400... Loss: 1.101957... Val Loss: 0.966977\n",
            "Epoch: 3/50... Step: 1500... Loss: 0.886722... Val Loss: 0.935833\n",
            "Epoch: 4/50... Step: 1600... Loss: 0.947901... Val Loss: 0.922210\n",
            "Epoch: 4/50... Step: 1700... Loss: 0.877379... Val Loss: 0.911337\n",
            "Epoch: 4/50... Step: 1800... Loss: 0.763719... Val Loss: 0.898494\n",
            "Epoch: 4/50... Step: 1900... Loss: 0.852731... Val Loss: 0.889472\n",
            "Epoch: 4/50... Step: 2000... Loss: 0.919317... Val Loss: 0.887968\n",
            "Epoch: 5/50... Step: 2100... Loss: 0.780253... Val Loss: 0.890822\n",
            "Epoch: 5/50... Step: 2200... Loss: 0.880471... Val Loss: 0.879840\n",
            "Epoch: 5/50... Step: 2300... Loss: 0.819938... Val Loss: 0.877095\n",
            "Epoch: 5/50... Step: 2400... Loss: 0.833218... Val Loss: 0.866966\n",
            "Epoch: 5/50... Step: 2500... Loss: 0.806697... Val Loss: 0.869106\n",
            "Epoch: 6/50... Step: 2600... Loss: 0.714596... Val Loss: 0.858352\n",
            "Epoch: 6/50... Step: 2700... Loss: 0.848768... Val Loss: 0.860715\n",
            "Epoch: 6/50... Step: 2800... Loss: 0.847283... Val Loss: 0.857360\n",
            "Epoch: 6/50... Step: 2900... Loss: 0.699850... Val Loss: 0.849064\n",
            "Epoch: 6/50... Step: 3000... Loss: 0.806650... Val Loss: 0.856535\n",
            "Epoch: 7/50... Step: 3100... Loss: 0.724742... Val Loss: 0.844457\n",
            "Epoch: 7/50... Step: 3200... Loss: 0.840201... Val Loss: 0.849089\n",
            "Epoch: 7/50... Step: 3300... Loss: 0.777697... Val Loss: 0.843171\n",
            "Epoch: 7/50... Step: 3400... Loss: 0.753718... Val Loss: 0.838806\n",
            "Epoch: 7/50... Step: 3500... Loss: 0.728839... Val Loss: 0.842646\n",
            "Epoch: 8/50... Step: 3600... Loss: 0.796942... Val Loss: 0.834945\n",
            "Epoch: 8/50... Step: 3700... Loss: 0.708851... Val Loss: 0.835641\n",
            "Epoch: 8/50... Step: 3800... Loss: 0.778574... Val Loss: 0.832823\n",
            "Epoch: 8/50... Step: 3900... Loss: 0.836560... Val Loss: 0.833527\n",
            "Epoch: 8/50... Step: 4000... Loss: 0.843969... Val Loss: 0.828304\n",
            "Epoch: 8/50... Step: 4100... Loss: 0.705938... Val Loss: 0.830001\n",
            "Epoch: 9/50... Step: 4200... Loss: 0.730458... Val Loss: 0.826952\n",
            "Epoch: 9/50... Step: 4300... Loss: 0.688154... Val Loss: 0.825421\n",
            "Epoch: 9/50... Step: 4400... Loss: 0.701814... Val Loss: 0.824729\n",
            "Epoch: 9/50... Step: 4500... Loss: 0.707433... Val Loss: 0.827400\n",
            "Epoch: 9/50... Step: 4600... Loss: 0.731133... Val Loss: 0.822960\n",
            "Epoch: 10/50... Step: 4700... Loss: 0.755200... Val Loss: 0.819648\n",
            "Epoch: 10/50... Step: 4800... Loss: 0.617936... Val Loss: 0.820644\n",
            "Epoch: 10/50... Step: 4900... Loss: 0.702467... Val Loss: 0.819678\n",
            "Epoch: 10/50... Step: 5000... Loss: 0.765233... Val Loss: 0.818009\n",
            "Epoch: 10/50... Step: 5100... Loss: 0.689197... Val Loss: 0.823622\n",
            "Epoch: 11/50... Step: 5200... Loss: 0.692674... Val Loss: 0.830910\n",
            "Epoch: 11/50... Step: 5300... Loss: 0.637605... Val Loss: 0.817127\n",
            "Epoch: 11/50... Step: 5400... Loss: 0.695769... Val Loss: 0.820643\n",
            "Epoch: 11/50... Step: 5500... Loss: 0.745724... Val Loss: 0.817220\n",
            "Epoch: 11/50... Step: 5600... Loss: 0.722219... Val Loss: 0.815919\n",
            "Epoch: 12/50... Step: 5700... Loss: 0.648810... Val Loss: 0.817507\n",
            "Epoch: 12/50... Step: 5800... Loss: 0.712009... Val Loss: 0.816673\n",
            "Epoch: 12/50... Step: 5900... Loss: 0.757596... Val Loss: 0.817731\n",
            "Epoch: 12/50... Step: 6000... Loss: 0.685910... Val Loss: 0.811737\n",
            "Epoch: 12/50... Step: 6100... Loss: 0.781174... Val Loss: 0.818028\n",
            "Epoch: 13/50... Step: 6200... Loss: 0.619617... Val Loss: 0.810407\n",
            "Epoch: 13/50... Step: 6300... Loss: 0.682749... Val Loss: 0.812012\n",
            "Epoch: 13/50... Step: 6400... Loss: 0.659313... Val Loss: 0.812891\n",
            "Epoch: 13/50... Step: 6500... Loss: 0.704443... Val Loss: 0.807712\n",
            "Epoch: 13/50... Step: 6600... Loss: 0.697941... Val Loss: 0.808952\n",
            "Epoch: 14/50... Step: 6700... Loss: 0.680118... Val Loss: 0.811416\n",
            "Epoch: 14/50... Step: 6800... Loss: 0.677553... Val Loss: 0.808127\n",
            "Epoch: 14/50... Step: 6900... Loss: 0.660708... Val Loss: 0.807628\n",
            "Epoch: 14/50... Step: 7000... Loss: 0.751767... Val Loss: 0.806279\n",
            "Epoch: 14/50... Step: 7100... Loss: 0.682985... Val Loss: 0.803312\n",
            "Epoch: 15/50... Step: 7200... Loss: 0.727900... Val Loss: 0.810199\n",
            "Epoch: 15/50... Step: 7300... Loss: 0.679868... Val Loss: 0.807144\n",
            "Epoch: 15/50... Step: 7400... Loss: 0.665277... Val Loss: 0.813146\n",
            "Epoch: 15/50... Step: 7500... Loss: 0.620003... Val Loss: 0.807966\n",
            "Epoch: 15/50... Step: 7600... Loss: 0.661371... Val Loss: 0.808580\n",
            "Epoch: 15/50... Step: 7700... Loss: 0.677515... Val Loss: 0.806981\n",
            "Epoch: 16/50... Step: 7800... Loss: 0.665565... Val Loss: 0.808843\n",
            "Epoch: 16/50... Step: 7900... Loss: 0.739321... Val Loss: 0.803387\n",
            "Epoch: 16/50... Step: 8000... Loss: 0.680915... Val Loss: 0.807075\n",
            "Epoch: 16/50... Step: 8100... Loss: 0.699279... Val Loss: 0.803489\n",
            "Epoch: 16/50... Step: 8200... Loss: 0.694474... Val Loss: 0.805910\n",
            "Epoch: 17/50... Step: 8300... Loss: 0.644011... Val Loss: 0.803799\n",
            "Epoch: 17/50... Step: 8400... Loss: 0.633749... Val Loss: 0.806449\n",
            "Epoch: 17/50... Step: 8500... Loss: 0.758404... Val Loss: 0.808432\n",
            "Epoch: 17/50... Step: 8600... Loss: 0.602425... Val Loss: 0.805535\n",
            "Epoch: 17/50... Step: 8700... Loss: 0.645780... Val Loss: 0.803501\n",
            "Epoch: 18/50... Step: 8800... Loss: 0.645393... Val Loss: 0.801125\n",
            "Epoch: 18/50... Step: 8900... Loss: 0.692177... Val Loss: 0.803425\n",
            "Epoch: 18/50... Step: 9000... Loss: 0.661011... Val Loss: 0.802295\n",
            "Epoch: 18/50... Step: 9100... Loss: 0.645499... Val Loss: 0.801390\n",
            "Epoch: 18/50... Step: 9200... Loss: 0.673991... Val Loss: 0.802810\n",
            "Epoch: 19/50... Step: 9300... Loss: 0.676464... Val Loss: 0.802115\n",
            "Epoch: 19/50... Step: 9400... Loss: 0.615231... Val Loss: 0.801798\n",
            "Epoch: 19/50... Step: 9500... Loss: 0.661489... Val Loss: 0.799229\n",
            "Epoch: 19/50... Step: 9600... Loss: 0.673533... Val Loss: 0.804484\n",
            "Epoch: 19/50... Step: 9700... Loss: 0.616261... Val Loss: 0.805228\n",
            "Epoch: 20/50... Step: 9800... Loss: 0.677018... Val Loss: 0.799544\n",
            "Epoch: 20/50... Step: 9900... Loss: 0.649253... Val Loss: 0.801147\n",
            "Epoch: 20/50... Step: 10000... Loss: 0.664782... Val Loss: 0.803411\n",
            "Epoch: 20/50... Step: 10100... Loss: 0.599645... Val Loss: 0.798054\n",
            "Epoch: 20/50... Step: 10200... Loss: 0.660964... Val Loss: 0.798787\n",
            "Epoch: 21/50... Step: 10300... Loss: 0.644821... Val Loss: 0.799256\n",
            "Epoch: 21/50... Step: 10400... Loss: 0.653346... Val Loss: 0.801035\n",
            "Epoch: 21/50... Step: 10500... Loss: 0.699329... Val Loss: 0.799091\n",
            "Epoch: 21/50... Step: 10600... Loss: 0.599591... Val Loss: 0.802520\n",
            "Epoch: 21/50... Step: 10700... Loss: 0.638890... Val Loss: 0.802269\n",
            "Epoch: 22/50... Step: 10800... Loss: 0.645127... Val Loss: 0.802691\n",
            "Epoch: 22/50... Step: 10900... Loss: 0.659623... Val Loss: 0.800404\n",
            "Epoch: 22/50... Step: 11000... Loss: 0.692861... Val Loss: 0.798757\n",
            "Epoch: 22/50... Step: 11100... Loss: 0.658160... Val Loss: 0.798718\n",
            "Epoch: 22/50... Step: 11200... Loss: 0.601708... Val Loss: 0.798951\n",
            "Epoch: 22/50... Step: 11300... Loss: 0.692262... Val Loss: 0.800768\n",
            "Epoch: 23/50... Step: 11400... Loss: 0.673239... Val Loss: 0.801878\n",
            "Epoch: 23/50... Step: 11500... Loss: 0.625622... Val Loss: 0.797554\n",
            "Epoch: 23/50... Step: 11600... Loss: 0.665106... Val Loss: 0.802923\n",
            "Epoch: 23/50... Step: 11700... Loss: 0.689951... Val Loss: 0.800214\n",
            "Epoch: 23/50... Step: 11800... Loss: 0.677875... Val Loss: 0.806113\n",
            "Epoch: 24/50... Step: 11900... Loss: 0.629730... Val Loss: 0.799603\n",
            "Epoch: 24/50... Step: 12000... Loss: 0.645088... Val Loss: 0.799936\n",
            "Epoch: 24/50... Step: 12100... Loss: 0.638562... Val Loss: 0.798737\n",
            "Epoch: 24/50... Step: 12200... Loss: 0.648962... Val Loss: 0.798366\n",
            "Epoch: 24/50... Step: 12300... Loss: 0.646684... Val Loss: 0.799773\n",
            "Epoch: 25/50... Step: 12400... Loss: 0.601265... Val Loss: 0.796626\n",
            "Epoch: 25/50... Step: 12500... Loss: 0.679341... Val Loss: 0.797711\n",
            "Epoch: 25/50... Step: 12600... Loss: 0.676957... Val Loss: 0.799439\n",
            "Epoch: 25/50... Step: 12700... Loss: 0.587886... Val Loss: 0.799969\n",
            "Epoch: 25/50... Step: 12800... Loss: 0.758723... Val Loss: 0.799396\n",
            "Epoch: 26/50... Step: 12900... Loss: 0.633720... Val Loss: 0.797637\n",
            "Epoch: 26/50... Step: 13000... Loss: 0.598418... Val Loss: 0.804284\n",
            "Epoch: 26/50... Step: 13100... Loss: 0.614177... Val Loss: 0.801979\n",
            "Epoch: 26/50... Step: 13200... Loss: 0.628508... Val Loss: 0.798637\n",
            "Epoch: 26/50... Step: 13300... Loss: 0.598358... Val Loss: 0.799861\n",
            "Epoch: 27/50... Step: 13400... Loss: 0.681407... Val Loss: 0.797950\n",
            "Epoch: 27/50... Step: 13500... Loss: 0.647394... Val Loss: 0.798420\n",
            "Epoch: 27/50... Step: 13600... Loss: 0.662033... Val Loss: 0.796352\n",
            "Epoch: 27/50... Step: 13700... Loss: 0.681054... Val Loss: 0.797740\n",
            "Epoch: 27/50... Step: 13800... Loss: 0.690646... Val Loss: 0.797830\n",
            "Epoch: 28/50... Step: 13900... Loss: 0.684403... Val Loss: 0.796821\n",
            "Epoch: 28/50... Step: 14000... Loss: 0.629454... Val Loss: 0.798750\n",
            "Epoch: 28/50... Step: 14100... Loss: 0.692140... Val Loss: 0.799057\n",
            "Epoch: 28/50... Step: 14200... Loss: 0.660866... Val Loss: 0.797814\n",
            "Epoch: 28/50... Step: 14300... Loss: 0.675221... Val Loss: 0.793221\n",
            "Epoch: 29/50... Step: 14400... Loss: 0.614873... Val Loss: 0.794416\n",
            "Epoch: 29/50... Step: 14500... Loss: 0.629581... Val Loss: 0.796060\n",
            "Epoch: 29/50... Step: 14600... Loss: 0.614088... Val Loss: 0.791709\n",
            "Epoch: 29/50... Step: 14700... Loss: 0.629560... Val Loss: 0.793346\n",
            "Epoch: 29/50... Step: 14800... Loss: 0.629577... Val Loss: 0.792375\n",
            "Epoch: 29/50... Step: 14900... Loss: 0.660413... Val Loss: 0.792085\n",
            "Epoch: 30/50... Step: 15000... Loss: 0.676037... Val Loss: 0.791904\n",
            "Epoch: 30/50... Step: 15100... Loss: 0.645596... Val Loss: 0.792102\n",
            "Epoch: 30/50... Step: 15200... Loss: 0.619509... Val Loss: 0.791781\n",
            "Epoch: 30/50... Step: 15300... Loss: 0.645383... Val Loss: 0.791848\n",
            "Epoch: 30/50... Step: 15400... Loss: 0.676503... Val Loss: 0.795728\n",
            "Epoch: 31/50... Step: 15500... Loss: 0.614156... Val Loss: 0.793113\n",
            "Epoch: 31/50... Step: 15600... Loss: 0.612696... Val Loss: 0.795504\n",
            "Epoch: 31/50... Step: 15700... Loss: 0.599217... Val Loss: 0.790806\n",
            "Epoch: 31/50... Step: 15800... Loss: 0.692045... Val Loss: 0.792552\n",
            "Epoch: 31/50... Step: 15900... Loss: 0.641844... Val Loss: 0.794870\n",
            "Epoch: 32/50... Step: 16000... Loss: 0.650390... Val Loss: 0.794628\n",
            "Epoch: 32/50... Step: 16100... Loss: 0.630818... Val Loss: 0.791180\n",
            "Epoch: 32/50... Step: 16200... Loss: 0.587453... Val Loss: 0.792713\n",
            "Epoch: 32/50... Step: 16300... Loss: 0.676913... Val Loss: 0.801470\n",
            "Epoch: 32/50... Step: 16400... Loss: 0.613511... Val Loss: 0.791781\n",
            "Epoch: 33/50... Step: 16500... Loss: 0.633115... Val Loss: 0.788776\n",
            "Epoch: 33/50... Step: 16600... Loss: 0.691884... Val Loss: 0.790574\n",
            "Epoch: 33/50... Step: 16700... Loss: 0.645784... Val Loss: 0.792693\n",
            "Epoch: 33/50... Step: 16800... Loss: 0.583142... Val Loss: 0.790778\n",
            "Epoch: 33/50... Step: 16900... Loss: 0.614024... Val Loss: 0.794096\n",
            "Epoch: 34/50... Step: 17000... Loss: 0.629371... Val Loss: 0.792984\n",
            "Epoch: 34/50... Step: 17100... Loss: 0.648920... Val Loss: 0.794251\n",
            "Epoch: 34/50... Step: 17200... Loss: 0.627063... Val Loss: 0.792562\n",
            "Epoch: 34/50... Step: 17300... Loss: 0.613967... Val Loss: 0.791843\n",
            "Epoch: 34/50... Step: 17400... Loss: 0.598328... Val Loss: 0.794063\n",
            "Epoch: 35/50... Step: 17500... Loss: 0.660871... Val Loss: 0.790195\n",
            "Epoch: 35/50... Step: 17600... Loss: 0.645187... Val Loss: 0.790842\n",
            "Epoch: 35/50... Step: 17700... Loss: 0.630429... Val Loss: 0.798019\n",
            "Epoch: 35/50... Step: 17800... Loss: 0.599522... Val Loss: 0.793882\n",
            "Epoch: 35/50... Step: 17900... Loss: 0.637850... Val Loss: 0.794217\n",
            "Epoch: 36/50... Step: 18000... Loss: 0.675777... Val Loss: 0.790120\n",
            "Epoch: 36/50... Step: 18100... Loss: 0.598629... Val Loss: 0.792047\n",
            "Epoch: 36/50... Step: 18200... Loss: 0.687394... Val Loss: 0.792084\n",
            "Epoch: 36/50... Step: 18300... Loss: 0.629572... Val Loss: 0.788409\n",
            "Epoch: 36/50... Step: 18400... Loss: 0.657890... Val Loss: 0.789735\n",
            "Epoch: 36/50... Step: 18500... Loss: 0.645168... Val Loss: 0.790101\n",
            "Epoch: 37/50... Step: 18600... Loss: 0.643223... Val Loss: 0.794494\n",
            "Epoch: 37/50... Step: 18700... Loss: 0.598605... Val Loss: 0.788941\n",
            "Epoch: 37/50... Step: 18800... Loss: 0.675949... Val Loss: 0.793313\n",
            "Epoch: 37/50... Step: 18900... Loss: 0.689279... Val Loss: 0.789605\n",
            "Epoch: 37/50... Step: 19000... Loss: 0.644674... Val Loss: 0.793185\n",
            "Epoch: 38/50... Step: 19100... Loss: 0.646038... Val Loss: 0.791606\n",
            "Epoch: 38/50... Step: 19200... Loss: 0.660825... Val Loss: 0.784923\n",
            "Epoch: 38/50... Step: 19300... Loss: 0.661030... Val Loss: 0.789178\n",
            "Epoch: 38/50... Step: 19400... Loss: 0.629848... Val Loss: 0.791868\n",
            "Epoch: 38/50... Step: 19500... Loss: 0.598452... Val Loss: 0.793235\n",
            "Epoch: 39/50... Step: 19600... Loss: 0.616305... Val Loss: 0.790353\n",
            "Epoch: 39/50... Step: 19700... Loss: 0.613954... Val Loss: 0.791263\n",
            "Epoch: 39/50... Step: 19800... Loss: 0.612601... Val Loss: 0.787176\n",
            "Epoch: 39/50... Step: 19900... Loss: 0.614048... Val Loss: 0.788508\n",
            "Epoch: 39/50... Step: 20000... Loss: 0.623754... Val Loss: 0.787945\n",
            "Epoch: 40/50... Step: 20100... Loss: 0.613476... Val Loss: 0.790135\n",
            "Epoch: 40/50... Step: 20200... Loss: 0.600050... Val Loss: 0.786518\n",
            "Epoch: 40/50... Step: 20300... Loss: 0.629608... Val Loss: 0.783278\n",
            "Epoch: 40/50... Step: 20400... Loss: 0.664449... Val Loss: 0.788153\n",
            "Epoch: 40/50... Step: 20500... Loss: 0.645128... Val Loss: 0.788929\n",
            "Epoch: 41/50... Step: 20600... Loss: 0.614125... Val Loss: 0.788096\n",
            "Epoch: 41/50... Step: 20700... Loss: 0.598643... Val Loss: 0.786251\n",
            "Epoch: 41/50... Step: 20800... Loss: 0.645261... Val Loss: 0.786534\n",
            "Epoch: 41/50... Step: 20900... Loss: 0.614043... Val Loss: 0.784294\n",
            "Epoch: 41/50... Step: 21000... Loss: 0.615205... Val Loss: 0.785734\n",
            "Epoch: 42/50... Step: 21100... Loss: 0.683846... Val Loss: 0.783764\n",
            "Epoch: 42/50... Step: 21200... Loss: 0.598316... Val Loss: 0.785902\n",
            "Epoch: 42/50... Step: 21300... Loss: 0.580671... Val Loss: 0.785392\n",
            "Epoch: 42/50... Step: 21400... Loss: 0.582708... Val Loss: 0.791834\n",
            "Epoch: 42/50... Step: 21500... Loss: 0.629689... Val Loss: 0.786661\n",
            "Epoch: 43/50... Step: 21600... Loss: 0.659354... Val Loss: 0.790582\n",
            "Epoch: 43/50... Step: 21700... Loss: 0.660831... Val Loss: 0.785668\n",
            "Epoch: 43/50... Step: 21800... Loss: 0.620032... Val Loss: 0.790610\n",
            "Epoch: 43/50... Step: 21900... Loss: 0.613445... Val Loss: 0.784163\n",
            "Epoch: 43/50... Step: 22000... Loss: 0.630930... Val Loss: 0.788983\n",
            "Epoch: 43/50... Step: 22100... Loss: 0.583224... Val Loss: 0.789875\n",
            "Epoch: 44/50... Step: 22200... Loss: 0.637003... Val Loss: 0.787377\n",
            "Epoch: 44/50... Step: 22300... Loss: 0.645143... Val Loss: 0.787914\n",
            "Epoch: 44/50... Step: 22400... Loss: 0.629678... Val Loss: 0.784442\n",
            "Epoch: 44/50... Step: 22500... Loss: 0.616819... Val Loss: 0.784416\n",
            "Epoch: 44/50... Step: 22600... Loss: 0.613961... Val Loss: 0.785304\n",
            "Epoch: 45/50... Step: 22700... Loss: 0.691997... Val Loss: 0.781774\n",
            "Epoch: 45/50... Step: 22800... Loss: 0.613957... Val Loss: 0.782416\n",
            "Epoch: 45/50... Step: 22900... Loss: 0.568429... Val Loss: 0.784869\n",
            "Epoch: 45/50... Step: 23000... Loss: 0.658209... Val Loss: 0.781625\n",
            "Epoch: 45/50... Step: 23100... Loss: 0.631129... Val Loss: 0.781344\n",
            "Epoch: 46/50... Step: 23200... Loss: 0.629609... Val Loss: 0.779707\n",
            "Epoch: 46/50... Step: 23300... Loss: 0.582753... Val Loss: 0.785180\n",
            "Epoch: 46/50... Step: 23400... Loss: 0.598319... Val Loss: 0.782548\n",
            "Epoch: 46/50... Step: 23500... Loss: 0.586317... Val Loss: 0.782454\n",
            "Epoch: 46/50... Step: 23600... Loss: 0.598373... Val Loss: 0.784441\n",
            "Epoch: 47/50... Step: 23700... Loss: 0.644307... Val Loss: 0.784919\n",
            "Epoch: 47/50... Step: 23800... Loss: 0.629601... Val Loss: 0.787150\n",
            "Epoch: 47/50... Step: 23900... Loss: 0.613979... Val Loss: 0.786063\n",
            "Epoch: 47/50... Step: 24000... Loss: 0.660818... Val Loss: 0.785875\n",
            "Epoch: 47/50... Step: 24100... Loss: 0.660823... Val Loss: 0.783935\n",
            "Epoch: 48/50... Step: 24200... Loss: 0.707613... Val Loss: 0.785058\n",
            "Epoch: 48/50... Step: 24300... Loss: 0.645235... Val Loss: 0.783393\n",
            "Epoch: 48/50... Step: 24400... Loss: 0.613946... Val Loss: 0.785284\n",
            "Epoch: 48/50... Step: 24500... Loss: 0.613946... Val Loss: 0.782450\n",
            "Epoch: 48/50... Step: 24600... Loss: 0.629589... Val Loss: 0.782222\n",
            "Epoch: 49/50... Step: 24700... Loss: 0.738941... Val Loss: 0.783967\n",
            "Epoch: 49/50... Step: 24800... Loss: 0.598320... Val Loss: 0.786792\n",
            "Epoch: 49/50... Step: 24900... Loss: 0.605084... Val Loss: 0.788289\n",
            "Epoch: 49/50... Step: 25000... Loss: 0.629655... Val Loss: 0.784381\n",
            "Epoch: 49/50... Step: 25100... Loss: 0.662260... Val Loss: 0.785432\n",
            "Epoch: 50/50... Step: 25200... Loss: 0.598322... Val Loss: 0.789505\n",
            "Epoch: 50/50... Step: 25300... Loss: 0.613954... Val Loss: 0.783333\n",
            "Epoch: 50/50... Step: 25400... Loss: 0.629881... Val Loss: 0.779434\n",
            "Epoch: 50/50... Step: 25500... Loss: 0.661819... Val Loss: 0.781977\n",
            "Epoch: 50/50... Step: 25600... Loss: 0.630934... Val Loss: 0.781743\n",
            "Epoch: 50/50... Step: 25700... Loss: 0.628758... Val Loss: 0.780370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxaHBrN32GHj"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngvqAKoj2GHj",
        "outputId": "c21e0196-e309-4532-ff98-ace8f10af31e"
      },
      "source": [
        "\n",
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda().type(torch.LongTensor), labels.type(torch.LongTensor).cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    #inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels)\n",
        "    test_losses.append(test_loss.item())\n",
        "    #print(output)\n",
        "    #print(output.squeeze())\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    #pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    #pred = torch.max(output.squeeze(), 1)[1]\n",
        "    pred = torch.argmax(output,dim=1, keepdim=True)\n",
        "    #print(pred)\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.786\n",
            "Test accuracy: 0.758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QigT9ttT2GHk"
      },
      "source": [
        "h = net.init_hidden(batch_size)\n",
        "prediction = []\n",
        "test_labels = []\n",
        "for inputs, labels in test_loader:\n",
        "  h = tuple([each.data for each in h])\n",
        "  inputs, labels = inputs.cuda().type(torch.LongTensor), labels.cuda().type(torch.LongTensor)\n",
        "  output, h = net(inputs, h)\n",
        "  pred = torch.argmax(output, dim=1, keepdim=True)\n",
        "  prediction.append(pred.tolist())\n",
        "  test_labels.append(labels.tolist())\n",
        "prediction = np.array(prediction).reshape(-1,)\n",
        "test_labels = np.array(test_labels).reshape(-1,)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FWVQ44lCHlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9ed70f-6ae6-4dd9-952f-1550f873fea1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(prediction, test_labels)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7635063559322034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV2LWSHTdkSu",
        "outputId": "1f8cc4e6-021a-4937-f3c7-ddac27e77d18"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, prediction))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.68      0.67       617\n",
            "           1       0.78      0.78      0.78      1531\n",
            "           2       0.79      0.78      0.78      1628\n",
            "\n",
            "    accuracy                           0.76      3776\n",
            "   macro avg       0.74      0.75      0.74      3776\n",
            "weighted avg       0.76      0.76      0.76      3776\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sQxzGU7dxdN",
        "outputId": "2f0ebd25-e78d-4495-c6d3-0fd66d26bfbd"
      },
      "source": [
        "a"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRboaGxPeDk5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}